% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model.R
\name{keyATM_model}
\alias{keyATM_model}
\title{Initialize a keyATM model}
\usage{
keyATM_model(files = NULL, dict = NULL, text_df = NULL,
  text_dfm = NULL, mode = "", extra_k = 1, covariates_data = NULL,
  covariates_formula = NULL, num_states = NULL, timestamps = NULL,
  encoding = "UTF-8", lowercase = TRUE, remove_numbers = TRUE,
  remove_punct = TRUE, remove_symbols = TRUE,
  remove_separators = TRUE, remove_twitter = FALSE,
  remove_hyphens = FALSE, remove_url = TRUE, stem_language = NULL,
  stopwords = NULL, alpha = 50/(length(dict) + extra_k), beta = 0.01,
  beta_s = 0.1, options = list())
}
\arguments{
\item{files}{names of each file to read (or a quanteda corpus object)}

\item{dict}{a quanteda dictionary or named list of character vectors}

\item{text_df}{directly passes a text in a data.frame}

\item{mode}{"basic", "cov", "tot", "totcov", and "ldaweight"}

\item{extra_k}{number of unseeded topics in addition to the topics seeded by
\code{dict}}

\item{covariates_data}{a data.frame or a tibble that is a covariate matrix. Columns are covariates.}

\item{covariates_formula}{formula for the covariates, for example, \code{~.} uses all variables}

\item{timestamps}{time data}

\item{encoding}{File encoding (Default: whatever \code{quanteda} guesses)}

\item{lowercase}{whether to transform each token to lowercase letters}

\item{remove_numbers}{whether to remove numbers}

\item{remove_punct}{whether to remove punctuation}

\item{remove_symbols}{whether to remove non-alphanumerical symbols}

\item{remove_separators}{whether to remove tabs, spaces, newlines, etc.}

\item{remove_twitter}{whether to remove Twitter detritus}

\item{remove_hyphens}{whether to split hyphenated words}

\item{remove_url}{whether to remove URLs}

\item{stem_language}{if not NULL, the language to use for stemming}

\item{stopwords}{if not NULL, a character vector of words to remove,
e.g. \code{quanteda::stopwords("english")}}

\item{alpha}{Starting value for all the model's topic proportion hyperparameters. Default: 50 / number of topics)}

\item{beta}{Hyperparameter for estimated word probabilities. Default: 0.01}

\item{beta_s}{Hyperparameter for seeded word probabilities. Default: 0.1}

\item{dtm}{Document-Term matrix from \code{quanteda} package}

\item{num_state}{numer of state in HMM model}

\item{gamma_1}{First Beta hyperparameter for probability of being drawn from a seeded topic. Default: 1.0}

\item{gamma_2}{Second Beta hyperparameter for probability of being drawn from a seeded topic. Default: 1.0}
}
\value{
A list containing: \describe{
        \item{W}{a list of vectors of word indexes}
        \item{Z}{a list of vectors of topic indicators isomorphic to W}
        \item{C}{a covariate matrix is there is an input}
        \item{X}{a list of vectors of seed indicators (0/1) isomorphic to W}
        \item{vocab}{a vector of vocabulary items}
        \item{files}{a vector of document filenames}
        \item{dict}{a tokenized version of the dictionary}
        \item{seeds}{a list of words for the seed words in dict, named by dictionary category}
        \item{extra_k}{how many extra non-seeded topics are required}
        \item{alpha}{a vector of topic proportion hyperparameters. If you use the model with covariates, it is not used.}
        \item{alpha_iter}{a list to store topic proportion hyperparameters}
        \item{Lambda_iter}{a list to store coefficients of the covariates}
        \item{S_iter}{a list to store states sampled in HMM}
        \item{tot_beta}{a list to store sampled beta parameters in topic-over-time}
        \item{sampling_info}{information related to sampling}
        \item{model_fit}{a list to store perplexity and log-likelihood}
        \item{gamma1}{First prior probability parameter for X (currently the same for all topics)}
        \item{gamma2}{Second prior probability parameter for X (currently the same for all topics)}
        \item{beta}{prior parameter for the non-seeded word generation probabilities}
        \item{beta_s}{prior parameter for the seeded word generation probabilities}
        \item{use_cov}{boolean, whether or not use the covariate}
        \item{num_states}{number of states in HMM}
        \item{timestamps}{time stamp for topic-over-time model}
        \item{visualize_keywords}{ggplot2 object}
        \item{call}{details of the function call}
        }
}
\description{
This function creates a list of word indexes W, topic indicators Z,
seed indicators X, a vocabulary list \code{vocab} from inputs.
We do not recommend to call this function directly. Please use \code{keyATM_read()}.
}
\details{
\code{Z} represents which topic a word topken was generated by.
It is initialized randomly
from \code{length(dict) + extra_k} topics, except when \code{dict}
assigns a word to a particular category, in which case this topic
indicator is assigned.
For example, if a word appears in the second category of \code{dict}
it will always be initialized as 1.

\code{X} is 1 when a word is generated from one of the topics from
the dictionary ('seeded') and 0 when it was generated from one of
the \code{extra_k} normal topics. \code{X} is initialized randomly
except when the word is contained in \code{dict}.

Note that all indicators are zero-based for ease of later processing
in C++, so \code{mod$vocab[mod$W + 1]} recovers the (tokenized) words
of the i-th document from model \code{mod}.

If \code{alpha} is a scalar this is the value given to all elements of
alpha. If it is a vector of the correct length those values are used
as the starting alphas.
}
